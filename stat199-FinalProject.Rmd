---
title: "Sentiment Analysis of Donald Trump's Twitter Use"
subtitle: "due Friday, Nov 20 at 11:59p"
author: "Ten Out of Ten: Arushi Bhatia, Luke Vermeer, Kevin Wang, Lauren May"
output: pdf_document
---

```{r installingPackages, echo=FALSE, warning=FALSE, message=FALSE}
r = getOption("repos")
r["CRAN"] = "http://cran.us.r-project.org"
options(repos = r)

# install.packages("viridis")
# install.packages("stopwords")
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("wordcloud")
# install.packages("sentimentr")
# install.packages("lubridate")
library(viridis)
library(stopwords)
library(tidyverse)
library(tidytext)
library(wordcloud)
library(sentimentr)
library(lubridate)
```

## Abstract
Donald Trump, before and during his presidency, has used Twitter as his main 
form of communication with his audience. Because of his major influence on the 
American population, we have chosen to explore the sentiments he displays in his 
tweets, which can give us helpful insight into the way he feels about certain 
topics and people. Therefore, our research question arises: How does Donald 
Trump's sentiment in his tweets vary across his "in-groups" and "out-groups?" 
We will define "in-groups" and "out-groups" in different ways, such as political 
party, gender, and topics that align with his beliefs vs. topics that don't 
align with his beliefs. For the topics, we also wanted to see how this sentiment 
changed over time. Using a sentiment analysis package, we determined the 
sentiment of each tweet. The topic/person discussed was also found using a word 
search among his tweets. Some of the tests/visualizations we utilized were a 
word cloud and a bar chart of his most used words, a segmented bar plot 
displaying the relative proportions of tweets with positive, neutral and 
negative overall sentiment towards the 11 people in our dataset, and a variety 
of tests comparing the true mean sentiment towards different groups (Democrats, 
Republicans, women, men). From the results of our tests and visualizations, 
there is enough evidence to suggest that Trump does tweet more positively about 
his in-groups than his out-groups. Additionally, our findings suggested that 
the true mean average sentiment of tweets about Democratic politicians was 
lower than those about Republicans. Similarly, when considering in-groups and 
out-groups by gender, Trump once again had significantly more positive sentiment 
towards his in-group - in this case, fellow males. We investigated some specific 
“hot topics” and how they changed over time, finding that his sentiment towards 
multiple topics did change pre- vs. post-election.

## Introduction and Data

### Background and Motivation
Relative to other forms of media, social media plays a much greater role in how 
people consume news in today’s technology-driven society. A study conducted in 
2016 by Pew Research points out how 62% of people get news on social media 
(Gottfried & Shearer, 2016). As a result, social media plays an integral role in 
politics, as the presence of a specific subset of information on a user’s feed 
can influence the way they categorize and see the world around them. With more 
and more individuals on social media such as Twitter, the role that this 
platform can play is significantly greater than before. 

Social media, and Twitter in particular, have become an increasingly large 
part of the political landscape in the wake of Donald Trump's 2016 election. 
Trump has been active on Twitter prior to and during his presidency and uses 
the platform as a tool to communicate with his constituency in real time, 
posting updates about policy, campaigning, and his feelings on everything 
from members of Congress to celebrities. He is one of the first politicians 
to use social media this frequently and has personally referred to his use of 
Twitter as “modern day presidential” (Trump, 2017). 

Donald Trump’s Twitter also has “unpresidented” reach among the American public, 
boasting a follower base of over 87 million. This makes him the second 
most-followed political personality and sixth most-followed overall account on 
Twitter (Wikipedia, 2020). On top of this, Trump’s Twitter also receives 
significant attention in the media. Over 850,000 news articles have referenced 
his Twitter use since 2016 and 31% of his tweets since then have received 
individual media coverage (Real Clear Politics, 2019).

### Research Questions
Because Trump uses Twitter to convey his political agendas in short blurbs, 
analyzing his tweets can give a unique insight into the way that he thinks. 
Of principal interest was the following research question: How does Donald
Trump's sentiment in his tweets vary across his "in-groups" and "out-groups?"
We will define "in-groups" and "out-groups" in different ways, such as political
party, gender, and topics that align with his beliefs vs. topics that don't 
align with his beliefs. For the topics, we also wanted to see how this sentiment
changed over time.

To answer this question, our team obtained a dataset of Donald Trump’s 
tweets (n = 53,697). In order to assess how his sentiment varies across 
people and various hot topics, we created indicator variables for different 
people and topics to indicate that a tweet referenced a specific person/topic. 
We then used the SentimentR package to calculate the overall sentiment of each 
tweet using the sentiment_by() function. Using the indicator variables, we were 
then able to distinguish the tweets into discernible categories, allowing us to 
conduct hypothesis tests and create interesting visualizations.

Our hypothesis regarding our research questions is that Trump’s tweets about
individuals and topics in his "out-group" have a greater proportion of tweets
with a negative sentiment. Similarly, we hypothesize that his tweets about
individuals and topics in his "in-group" will have a greater proportion of 
tweets with a positive sentiment. We will define in-group and out-group in 
different ways, and thus evaluate it from different perspectives.

### Our Data
The data set was extracted from a website-TrumpTwitterArchive.com. The original 
curator of the data created their own Twitter scraper in order to obtain the 
data. They utilized Python, Selenium (which is a software suite that allows the 
automation of tests utilizing web browsers), and Tweepy (a Python library for 
accessing the Twitter API). Since Twitter makes it challenging to scrape all of 
a user’s tweets in one go, the way to get around this is to individually search 
for a specific day and extract all the tweets from that user on that specific 
day. To do this manually would take ages, but the scraper that the curator 
built allows for automated accessing for any desired day and also a range of 
days. The scraper then obtains the tweet ID, which contains all of the metadata 
of the tweet, and then uses the metadata to obtain all the other information 
about the tweet (such as the text, timestamp, number of favorites, etc.). This 
other information is then compiled into a data set, which is made available to 
the public. This data set is updated every minute, which also means that deleted 
tweets would most likely also appear in this data set. However, as noted on
the website, many of the tweets are missing, either due to them being deleted
before the data set was updated, or other reasons.

This data set includes 53,697 observations. Each individual observation is one 
of President Donald Trump’s tweets. The original data set contains 7 variables: 
source, text, created_at, retweet_count, favorite_count, is_retweeted, id_str. 
The descriptions of each of the original variables is given below. 

- source: Original source where tweet was posted 

- text: text of the tweet 

- created_at: Date and time the tweet was posted/created, provides context

- retweet_count: number of retweets 

- favorite_count: number of favorites 

- is_retweeted: whether or not the tweet was originally posted on a different 
account and Trump retweeted 

- id_str: The scrape.py script collects tweet ids. If you know a tweet's ID 
number, you can get all the information available about that tweet using Tweepy 

#### Setting Up Our Data


Our first step in analyzing the relationships between subject and sentiment of 
President Donald Trump’s tweets was to manipulate the data set, creating some 
new variables that we could use for analysis. We started by creating a set of 
identifier variables for different people that his tweets might be about. These 
variables were created using multiple mutate commands to set them as either 1
or 0, 1 if the person or topic was mentioned in a tweet, and 0 if they weren’t. 

We created these variables for a total of 11 relevant political figures: 
Barack Obama, Joe Biden, Hillary Clinton, Alexandria Ocasio-Cortez, Nancy 
Pelosi, Kamala Harris, Mike Pence, Mitch McConnell, Amy Coney Barrett, 
Dr. Anthony Fauci and Nikki Haley. For each of the person identifier variables, 
we searched for people’s full names, their Twitter handles, and 
commonly-used nicknames to determine whether or not a particular tweet was about 
them. 

We also repeated the same process to create topical identifier variables for a 
range of subjects that are prevalent in the nation’s political discourse. The 
topics were as follows: COVID-19, climate change, abortion, the Black Lives 
Matter movement, guns, news, immigration, Russia, and the United States. For 
each topic we searched for the name of the thing outright (such as “BLM” or 
“climate change”), as well as words and phrases that are commonly used in 
conjunction with these topics. For example, tweets that mentioned ICE or the 
term “border wall” were categorized under immigration, and tweets about CNN, 
FOX News and “media” all went under the “news” topic. 

Next, using the pivot command in R, we created a variable called 
“person,”  and manipulated our original data set into a data set that allowed us
to count tweets that included multiple people as an observation that
counted towards both/all of the mentioned people, as it was a categorical 
variable that told us which of the identifier variables for people were equal 
to “1” for each tweet. As a result, some of the tweets were the same in this
new pivoted data set, but it allowed us to do our analysis in a much more 
effective and representative manner.

From the new “person” variable, we created two new variables called party and 
gender. The party variable separated the 11 people we were looking at into 
either Democrats or Republicans and assigned tweets about them to the 
appropriate party category. We did the same for the gender of each of these 
11 people, and added another "gender" variable categorizing the tweet as 
either about a "male" or "female." 

We did a similar pivoting process for the topic variables.

Next, we used the package SentimentR to identify the sentiment of each of 
Trump’s tweets. For each tweet, we created a new variable called ave_sentiment 
that contained the raw, numeric sentiment score of the text. This sentiment
score was calculated using the sentiment_by() function. The function finds the 
mean sentiment score of the entire tweet by averaging the individual sentiment
scores of the words in the tweet. We then used the mutate command to create a 
new variable called posNeg that grouped sentiment scores into three categories: 
positive, neutral, or negative. Finally, we used the separate command in R to 
break up the variable “created_at” into two separate variables for date and 
time. After this, each observation had a date variable in the mm/dd/yy format 
and a time variable in the 24-hour time format. 


## Methodology 
We used the following variables in the data set to address our research 
question:


- text: the full text of the tweet.

- obama: 1 or 0 for whether the tweet talks about Barack Obama.

- biden: 1 or 0 for whether the tweet talks about Joe Biden.

- pelosi: 1 or 0 for whether the tweet talks about Nancy Pelosi.

- kamala: 1 or 0 for whether the tweet talks about Kamala Harris.

- hillary: 1 or 0 for whether the tweet talks about Hillary Clinton.

- aoc: 1 or 0 for whether the tweet talks about Alexandria Ocasio-Cortez.

- pence: 1 or 0 for whether the tweet talks about Mike Pence.

- mcconnell: 1 or 0 for whether the tweet talks about Mitch McConnell.

- fauci: 1 or 0 for whether the tweet talks about Dr.  Anthony Fauci.

- amy: 1 or 0 for whether the tweet talks about Amy Coney Barrett.

- nikki: 1 or 0 for whether the tweet talks about Nikki Haley.

- covid: 1 or 0 for whether the tweet talks about COVID-19.

- climateChange: 1 or 0 for whether the tweet talks about climate change.

- abortion: 1 or 0 for whether the tweet talks about abortion.

- blm: 1 or 0 for whether the tweet talks about the Black Lives Matter movement.

- guns: 1 or 0 for whether the tweet talks about guns.

- news: 1 or 0 for whether the tweet talks about news media.

- usa: 1 or 0 for whether the tweet talks about the United States.

- russia: 1 or 0 for whether the tweet talks about Russia.

- immigration: 1 or 0 for whether the tweet talks about immigration.

- person: categorical variable for the name of the person that the tweet is 
about (from among the 11 looked at in this analysis).

- party: political party of the person who is talked about in the tweet 
(either democrat or republican).

- gender: gender of the person who is talked about in the tweet (either male or 
female).

- ave_sentiment: numeric sentiment score of the tweet.

- posNeg: categorical sentiment of the tweet (either positive, neutral or 
negative).

- date: date that the tweet was posted (mm/dd/yy).

- time: time that the tweet was posted (24-hour format).

```{r people, echo=FALSE, warning=FALSE, message=FALSE}
trumptweets <- read_csv("data/trumptweetCSV.csv") 
trumptweets <- trumptweets %>%  
   mutate(obama = case_when((grepl("Obama", text , ignore.case = TRUE) | 
                              grepl("Barack", text , ignore.case = TRUE)) & 
                            !(grepl("Michelle", text , ignore.case = TRUE))~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(biden = case_when((grepl("Biden", text , ignore.case = TRUE) | 
                              grepl("Joe", text , ignore.case = TRUE)) ~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(pelosi = case_when((grepl("Pelosi", text , ignore.case = TRUE) | 
                              grepl("Nancy", text , ignore.case = TRUE)) &
                            ! grepl("@NancyMace", text, ignore.case = TRUE)~ 1,
                            TRUE ~0))


trumptweets <- trumptweets %>%  
   mutate(kamala = case_when((grepl("Kamala", text , ignore.case = TRUE))~ 1,
                            TRUE ~0))


trumptweets <- trumptweets %>%  
   mutate(hillary = case_when((grepl("Hillary", text , ignore.case = TRUE) | 
                              grepl("Clinton", text , ignore.case = TRUE)) & 
                        !(grepl("Bill Clinton", text , ignore.case = TRUE))~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(aoc = case_when((grepl("AOC", text , ignore.case = TRUE) | 
                              grepl("Ocasio", text , ignore.case = TRUE) |
                            grepl("Cortez", text , ignore.case = TRUE)|
                             grepl("Alexandria", text , ignore.case = TRUE))~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(pence = case_when((grepl("Pence", text , ignore.case = TRUE)) ~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(nikki = case_when((grepl("Nikki Haley", text , ignore.case = TRUE)| 
                              grepl("Nikki", text , ignore.case = TRUE)) ~ 1,
                            TRUE ~0))


trumptweets <- trumptweets %>%  
  mutate(mcconnell = case_when(((grepl("McConnell", text , ignore.case = TRUE) | 
                              grepl("Mitch", text , ignore.case = TRUE) |
                            grepl("@Team_Mitch", text , ignore.case = TRUE)) &
                        ! grepl("@mitchellvii", text , ignore.case = TRUE))~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(fauci = case_when((grepl("Fauci", text , ignore.case = TRUE)) ~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(amy = case_when((grepl("Coney Barrett", text , ignore.case = TRUE) | 
                             grepl("ACB", text , ignore.case = TRUE)| 
                             grepl("Judge Amy", text , ignore.case = TRUE)) ~ 1,
                            TRUE ~0))
```


```{r topics, echo=FALSE, warning=FALSE, message=FALSE}
trumptweets <- trumptweets %>%  
   mutate(covid = case_when((grepl("COVID", text , ignore.case = TRUE) | 
                              grepl("Corona", text , ignore.case = TRUE) |
                      grepl("Chinese virus", text , ignore.case = TRUE) |
                        grepl("China virus", text , ignore.case = TRUE) |
                        grepl("Chinese plague", text, ignore.case = TRUE) |
                        grepl("Wuhan virus", text , ignore.case = TRUE) |
                        grepl("Kung flu", text , ignore.case = TRUE)|
                        grepl("cdc", text , ignore.case = TRUE)|
                        grepl("fauci", text , ignore.case = TRUE)) ~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(climateChange = case_when((grepl("Climate change", text , 
                                           ignore.case = TRUE) | 
                          grepl("Global warming", text , ignore.case = TRUE) |
                      grepl("Environment", text , ignore.case = TRUE) |
                grepl("Paris Accord", text , ignore.case = TRUE) |
                 grepl("Paris Climate Agreement", text, ignore.case = TRUE) |
                      grepl("Pollute", text , ignore.case = TRUE) |
                      grepl("Pollution", text , ignore.case = TRUE)|
                      grepl("Greta Thunberg", text, ignore.case = TRUE)|
                      grepl("Greta", text, ignore.case = TRUE)) ~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(abortion = case_when((grepl("Abortion", text , ignore.case = TRUE) | 
                        grepl("Planned parenthood", text , ignore.case = TRUE) |
                      grepl("Abort", text , ignore.case = TRUE) |
                        grepl("pro-life", text , ignore.case = TRUE) |
                        grepl("pro-choice", text , ignore.case = TRUE)) ~ 1,
                            TRUE ~0))


trumptweets <- trumptweets %>%  
   mutate(blm = case_when((grepl("BLM", text , ignore.case = TRUE) | 
                       grepl("Black lives matter", text , ignore.case = TRUE) |
                      grepl("loot", text , ignore.case = TRUE) |
                        grepl("riot", text , ignore.case = TRUE)) ~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(guns = case_when((grepl("NRA", text , ignore.case = TRUE) | 
                          grepl("Second amendment", text , ignore.case = TRUE) |
                      grepl("gun", text , ignore.case = TRUE) |
                        grepl("bear arms", text , ignore.case = TRUE) |
                        grepl("rifle", text , ignore.case = TRUE) ) ~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(news = case_when((grepl("news", text , ignore.case = TRUE) |
                      grepl("CNN", text , ignore.case = TRUE) |
                        grepl("Fox", text , ignore.case = TRUE) |
                        grepl("media", text , ignore.case = TRUE)) ~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(usa = case_when((grepl("usa", text , ignore.case = TRUE) | 
                              grepl("america", text , ignore.case = TRUE) |
                      grepl("united states", text , ignore.case = TRUE) |
                        grepl("our country", text , ignore.case = TRUE)) ~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(russia = case_when((grepl("russia", text , ignore.case = TRUE) | 
                              grepl("putin", text , ignore.case = TRUE)| 
                            grepl("communism", text , ignore.case = TRUE)) ~ 1,
                            TRUE ~0))

trumptweets <- trumptweets %>%  
   mutate(immigration = case_when((grepl("immigrants", text , 
                                         ignore.case = TRUE) | 
                              grepl("immigration", text , ignore.case = TRUE) |
                      grepl("foreigner", text , ignore.case = TRUE) |
                        grepl("open border", text , ignore.case = TRUE) |
                        grepl("the wall", text , ignore.case = TRUE) |
                        grepl("border wall", text , ignore.case = TRUE)|
                        grepl("Mexicans", text , ignore.case = TRUE)|
                        grepl("refugee", text , ignore.case = TRUE)|
                        grepl("ice", text , ignore.case = TRUE)|
                        grepl("border patrol", text , ignore.case = TRUE)|
                        grepl("cages", text , ignore.case = TRUE)) ~ 1,
                            TRUE ~0))


trumptweets$element_id <- 1:nrow(trumptweets) 
```

We created multiple visualizations to help us explore our data. The first 
visualization we used was a word cloud, powered by the wordcloud package in R. 
The purpose of this visualization is to summarize what words are most commonly 
found in Donald Trump’s tweet. In a word cloud, the 100 most common words found 
in Trump’s tweets are displayed with larger sizes corresponding to more frequent 
instances of the word in question. We used this visualization to give a broad 
overview of what is contained in the tweets that make up the data set and to 
give a glimpse into the overall tone of Trump’s twitter use. We also thought 
that a visualization of this kind might reveal some overarching common themes 
in his tweets. Given the results, we can see that some of the words he most 
commonly uses are "great", "Trump", "president", "people", "country", "America", 
and "time." While these words don’t necessarily indicate the full scope of what 
he discusses on his Twitter account, we notice that most of his tweets are in 
regard to his role as the President of the United States. In addition, his most 
commonly used words are quite polarizing in that he uses many positive words 
such as “great”, “good”, “strong”, and “nice” while also using many negative 
words such as “fake”, “false”, “bad”, and “crime”. 

Our second visualization was a bar chart, showing the twenty most common words 
used by Trump on Twitter and the number of times they were used. This graph 
contains similar information to the word cloud but helps give a more detailed 
and objective view, allowing us to directly see which words he uses and how much 
he uses them. From this visualization, we can confirm what the world cloud 
suggested that the most common words Trump uses are, in fact, “great,” “Trump,” 
and “president.” Trump’s tweets have actually used the word “great” well over 
7000 times, making it more used than any other word by roughly 100 times used. 
His next most-used word, “Trump,” was used over 6000 times and his first name, 
“Donald,” was found in the text of his tweets nearly 2000 times as well. 

Figure 3 shows the relative proportions of tweets with positive, neutral and 
negative overall sentiment that Donald Trump has shared about each of the people 
covered in our data set. By creating a percent stacked bar plot, we were able to 
actively compare the sentiments Trump tends to have towards specific people, 
making it easier to visualize the results. Overall, it appears that Alexandria 
Ocasio-Cortez, Hillary Clinton, and Nancy Pelosi received the highest proportion 
of tweets with negative sentiment. Amy Coney Barrett had the lowest proportion 
of negative tweets, followed by Vice President Mike Pence. Looking at positive
tweet proportions, Senate Majority Leader Mitch McConnell had the highest 
proportion of positive tweets while Amy Coney Barrett, Mike Pence, and Nikki 
Haley also received a significant majority of tweets with a positive sentiment. 
These results were particularly interesting because it shows that Trump tends to 
tweet about people of the same party with positive sentiment at a greater 
proportion compared to the people of the Democratic party. We will explore this
further with a Chi-squared test to see if people mentioned in his tweet and 
sentiment are independent.

The purpose of Figure 4 is to explore the different sentiment Trump displays
towards male versus female politicians. We decided to look at this based
on party affiliation, because we believed that the results could be different
depending on if we were considering a Republican female politician versus a 
Democrat female politician (we wanted to learn if he had a different 
sentiment towards strictly males or females, or whether it had to also
do with politician affiliation). This visualization shows that when Donald Trump 
discusses Democratic politicians, he has a similar median sentiment towards male 
and female, which is fairly close to neutral. We also noticed that for this 
visualization, the male Democrats had a larger range of sentiments than the 
female Democrats, but the lowest score was given to a female Democratic
politician. In the visualization of male and female Republicans, the 
females had a slightly higher average sentiment compared to their male 
counterparts. This could indicate that he talks about males in his party in a 
less positive manner as compared to the females. We also recognized that, again, 
the male Republicans had a larger range of sentiments than the female 
Republicans, showing that his sentiments cover a larger range of positive
and negative sentiments when talking about Republican males. We will explore
this further with a Chi-squared test to see if party of the politician mentioned
in his tweet and sentiment are independent, and if we have enough evidence to 
suggest that they are dependent, then we will use a t-test to see if there
is enough evidence to suggest that he talks, on average, more 
negatively about Democrats than Republicans. Similarly, we will also do another
Chi-squared test to investigate if gender of the politician mentioned in his
tweet and sentiment of the tweet are independent, and if we have enough evidence
to suggest that they are dependent, then we will use a t-test to see if 
there is enough evidence to suggest that he talks, on average, more positively 
about males than females.

Figure 5 shows the relative proportions of tweets with positive, neutral and 
negative overall sentiment that Donald Trump has shared about each of the topics
we covered in our data set. By using a percent stacked bar plot, we could see
the percentages side-by-side. The results here are somewhat interesting and go 
contrary to what we expected to see with this graph. While Trump was, as we 
predicted, very positive on average towards guns and the United States, a 
relatively high proportion of his tweets were also positive towards immigration 
and the Black Lives Matter movement, two topics we identified as being in his 
out-group. He was also most negative towards Russia, a subject we categorized as 
in-group for him because of his positive relationship with Vladimir Putin. This
inconsistency with our prediction prompted us to explore how his sentiment may 
have changed over time.

Figure 6 allows us to see the change in Donald Trump’s sentiments towards 
specific “hot button topics” over time. We compiled all the tweets into 
a line plot with time as the x-axis and average sentiment as the y-axis. By 
taking the average sentiment of each topic by year, we were able to create this 
visualization and see how his sentiments in his tweets changed when discussing 
some specific topics. Sentiment scores for tweets about each of the four topics 
covered (immigration, guns, climate change and news) were averaged by year and 
plotted on a line graph. This allows us to see how his sentiment towards each of 
these subjects on Twitter has evolved over time. These four topics were chosen 
because they have been prevalent for a long time in the political discourse of 
the United States as opposed to something like COVID-19 or the Black Lives 
Matter movement. This meant that we could more fully track the change in his 
sentiment towards them over the time period of our data set. We also added a 
horizontal red line denoting a 0 sentiment score to make it more clear where 
his sentiments were positive and where they were negative, as well as a vertical 
blue dashed line at the year 2016 to show how sentiments changed after his 
election to the office of US President. To investigate this further, we will do 
a CLT-based t-test to see if there is enough evidence to suggest that the mean
sentiment score for tweets on a specific topic before Trump was elected (before
2016) is not equal to the mean sentiment score for tweets after he was elected.
We will do this for the different topics shown on the visualization.



\newpage 
```{r creatingSentimentDataset, echo=FALSE, warning=FALSE, message=FALSE}
trumptweetsSentiment <- sentiment_by(trumptweets$text)
tweetsWithSentiment <- left_join(trumptweets, trumptweetsSentiment, 
                                 by = "element_id")

tweetsWithSentiment <- tweetsWithSentiment %>% 
   mutate(posNeg = case_when(ave_sentiment> 0 ~ "positive", 
                             ave_sentiment< 0 ~ "negative", 
                             ave_sentiment==0 ~ "neutral"))

tweetsWithSentimentWithoutLink <- tweetsWithSentiment %>% 
  filter(!grepl("^https*", text))
view(tweetsWithSentimentWithoutLink)
```

```{r wordCloud, echo=FALSE, warning=FALSE, message=FALSE}
justWords <- tweetsWithSentimentWithoutLink %>%
  unnest_tokens(word, text)

freqWords <- justWords %>%
  anti_join(get_stopwords(source = "smart"))  %>%
  count(word) %>%
  arrange(desc(n)) %>% 
   filter(!(word=="t.co" | word=="realdonaldtrump"| word=="https" | word=="rt"| 
      word=="amp" | word=="http" | word =="10" | word=="2015" | word=="2016"))
wordCloud <- freqWords %>% with(wordcloud(word, n, max.words = 100))
```

Figure 1: Word cloud of the top 100 words Donald Trump uses in his tweets. Some
of the words that were not part of the actual text of the tweet or were
artifacts of tweets (such as URLs, account names, and years) were removed to 
clean the data.

\newpage 

```{r wordFreqGraph, echo=FALSE, warning=FALSE, message=FALSE}
freqChart <- freqWords %>%
  top_n(20) %>%
  ggplot(aes(fct_reorder(word, n), n)) +
    geom_col(fill = "pink", color = "black") +
    coord_flip() + 
    theme_minimal() +
    labs(title = "Frequency of words in Donald Trump's tweets",
         subtitle = "Top 20 word displayed",
         y = "Frequency",
         x = "Words")

freqChart
```

Figure 2: Frequency of Donald Trump's top 20 words that are used in his tweets.
Just like in Figure 1, some of the words that were not part of the actual text 
of the tweet or were artifacts of tweets (such as URLs, account names, and 
years) were removed to clean the data.

```{r creatingNewDataFrameWithPeople, echo=FALSE, warning=FALSE, message=FALSE}

peopleData <- tweetsWithSentimentWithoutLink %>%
  pivot_longer(obama:amy, names_to = "person", values_to = "existenceOfPerson")

peopleData <- peopleData %>% filter(existenceOfPerson==1)

ggplot(data=peopleData, aes(x=person, fill = factor(posNeg))) +
  geom_bar(position = "fill") + 
  labs(title="Lowest proportion of tweets with negative sentiment were tweets
mentioning Amy Coney Barrett and Mike Pence",
                  x="Politician",y ="Percentage of tweets", fill="Sentiment") + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
Figure 3: Illustrates the proportion of tweets with average negative (<0), 
neutral (=0), and positive (>0) sentiment that mention a specific politician.

```{r hypTestChiPeopleSentiment, eval=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
chisq.test(table(peopleData$person, 
                 peopleData$posNeg))
```


\newpage 
```{r partyAndGender, echo=FALSE, warning=FALSE, message=FALSE}
peopleData <- peopleData %>% 
   mutate(party=case_when((person == "obama" |
               person == "biden"|
               person == "kamala" | 
               person == "pelosi" | 
               person == "aoc"|
                  person == "hillary") ~ "Democratic",
               (person == "pence" |
                   person == "amy" |
                   person == "niki" |
                  person == "mcconnell") ~ "Republican"))

peopleData <- peopleData %>% 
   mutate(gender=case_when((person=="obama" |
              person=="biden"|
               person=="pence"|
               person=="fauci"| 
               person=="mcconnell") ~ "Male",
               (person=="kamala" |
                   person=="pelosi" |
                   person=="aoc"|
                   person=="amy" |
                   person=="nikki"|
                  person=="hillary") ~ "Female"))

ggplot(data = peopleData %>% 
          filter(party=="Democratic" | party == "Republican"), 
       mapping = aes(x = party, y = ave_sentiment,color=gender)) +
   geom_boxplot() +
labs(title = "Overall more positive sentiment in tweets mentioning Republicans",
       subtitle="Generally lower sentiment for Democratic females vs. males, 
   generally higher sentiment for Republican females vs. males",
        x = "Party", y = "tweet Average Sentiment Score") + 
   geom_hline(yintercept=0, linetype="dashed", color = "red")
```

Figure 4: Boxplot showing the average sentiment scores for tweets, divided by
political party of the person mentioned in the tweet, and split within
party to show any differences in how he talks about politicians of
different genders within either the Democratic or Republican party.

\newpage 
```{r hypTest, eval=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
dems <- peopleData %>%
  filter(party=="Democratic")

repubs <- peopleData %>%
  filter(party=="Republican")

chisq.test(table(peopleData$party, 
                 peopleData$posNeg))

t.test(dems$ave_sentiment, 
       repubs$ave_sentiment,
       mu = 0,
       var.equal = FALSE,
       alternative = "less",
       conf.level = 0.95)


male <- peopleData %>%
  filter(gender=="Male")

female <- peopleData %>%
  filter(gender=="Female")

chisq.test(table(peopleData$gender, 
                 peopleData$posNeg))

t.test(male$ave_sentiment, 
       female$ave_sentiment,
       mu = 0,
       var.equal = FALSE,
       alternative = "greater",
       conf.level = 0.95)
```

```{r peopleStackedPercentage, echo=FALSE, warning=FALSE, message=FALSE}
topicData <- tweetsWithSentimentWithoutLink %>%
 pivot_longer(covid:immigration, names_to = "topic", values_to = "existenceOfTopic")

topicData <- topicData %>% filter(existenceOfTopic==1)
   ggplot(data=topicData, aes(x=topic, fill = factor(posNeg))) +
    geom_bar(position = "fill") + 
   labs(title="Highest proportion of positive tweets is about USA, lowest 
is about Russia",
   x="Topic",y ="Percentage of tweets", fill="Sentiment") + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Figure 5: Illustrates the proportion of tweets with average negative (<0), 
neutral (=0), and positive (>0) sentiment that mention a specific topic.

\newpage

```{r topicsAcrossTime, echo=FALSE, warning=FALSE, message=FALSE}
tweetsWithSentimentDateTime <- tweetsWithSentimentWithoutLink %>%
 separate(created_at, c("date", "time"), sep = " ")

tweetsWithSentimentDateTimeFormat <- tweetsWithSentimentDateTime %>%
 mutate(date = as.Date(date, tryFormats = c("%m/%d/%y")))%>%
 pivot_longer(covid:immigration, names_to = "topic", values_to = 
                 "existenceOfTopic") %>%
 filter(existenceOfTopic == 1)

tweetsWithSentimentDateTimeFormatGroup <- tweetsWithSentimentDateTimeFormat %>%
   mutate(month = format(date, "%m"), year = format(date, "%Y")) %>%
   group_by(topic, year) %>% 
   summarize(avgSentimentForTopic = mean(ave_sentiment))

temp <- tweetsWithSentimentDateTimeFormatGroup %>% filter(topic=="climateChange"
   | topic=="news" | topic == "guns" | topic == "immigration" ) %>% 
   filter(!is.na(year))

ggplot(temp, 
       aes(x= year, y = avgSentimentForTopic, color = topic, 
           group=topic)) + theme(plot.margin = unit(c(1,0,1,0), "cm")) + 
   geom_point() + 
   geom_line() + 
   geom_vline(xintercept = "2016", linetype="dotted", 
                color = "blue", size=1.5) +
   labs(title = "Average sentiment for specific topics across the years",
       subtitle="Blue line indicates Trump's election, 
immigration and news follow similar patterns",
   x = "Year", y = "Tweet Average Sentiment Score Per Topic", color="Topic") + 
   geom_hline(yintercept=0, linetype="dashed", color = "red")
```

Figure 6: Shows change of average sentiment of tweets referring to a specific 
topic across the years. Only showing a few topics, we selected the ones
that have been tweeted about for a long time. The vertical blue line indicates
when Trump first became elected.

```{r hypTest2, eval=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
yearVar <- tweetsWithSentimentDateTimeFormat  %>%
   mutate(year = year(date))

#CLIMATE CHANGE
pre2016CC <- yearVar %>%
  filter(year<2016 & topic=="climateChange")

post2016CC <- yearVar %>%
  filter(year>=2016 & topic=="climateChange")

t.test(pre2016CC$ave_sentiment, 
       post2016CC$ave_sentiment,
       mu = 0,
       var.equal = FALSE,
       alternative = "two.sided",
       conf.level = 0.95)

#GUNS 
pre2016guns <- yearVar %>%
  filter(year<2016 & topic=="guns")

post2016guns <- yearVar %>%
  filter(year>=2016 & topic=="guns")

t.test(pre2016guns$ave_sentiment, 
       post2016guns$ave_sentiment,
       mu = 0,
       var.equal = FALSE,
       alternative = "two.sided",
       conf.level = 0.95)


#IMMIGRATION 
pre2016imm <- yearVar %>%
  filter(year<2016 & topic=="immigration")

post2016imm <- yearVar %>%
  filter(year>=2016 & topic=="immigration")

t.test(pre2016imm$ave_sentiment, 
       post2016imm$ave_sentiment,
       mu = 0,
       var.equal = FALSE,
       alternative = "two.sided",
       conf.level = 0.95)


#NEWS
pre2016News <- yearVar %>%
  filter(year<2016 & topic=="news")

post2016News <- yearVar %>%
  filter(year>=2016 & topic=="news")

t.test(pre2016News$ave_sentiment, 
       post2016News$ave_sentiment,
       mu = 0,
       var.equal = FALSE,
       alternative = "two.sided",
       conf.level = 0.95)

```
\newpage 


## Results
**Independence of person and sentiment:** In order to determine whether the 
variables person (the person Donald Trump discusses in his tweet) and posNeg 
(categorical sentiment of the tweet) are dependent, a chi-square test was used. 
The null hypothesis, $H_0$, is that the person discussed and the categorical 
sentiment of the tweet are independent, or in other words, there is no 
association between the two variables. This is being tested against the 
alternative hypothesis, which is that the person discussed and the categorical 
sentiment of the tweet are dependent, or in other words, there is an association 
between the two variables. We used the chi-square test to conduct this 
hypothesis test at the $alpha$ = 0.05 significance level. Under the assumption 
that the null hypothesis is true, the chi-square test statistic follows a 
Chi-square distribution with degrees of freedom equal to 
(11-1)x(3-1) = (10)x(2) = 20. The value of our test statistic, chi-square, is 
240.26. The p-value of our chi-square test is less than 2.2e-16, which is close 
to zero and less than the significance level of 0.05. This means we reject the 
null hypothesis. In the context of the data, we are concluding that there is 
sufficient evidence to suggest that the person discussed and the categorical 
sentiment are dependent or that there is sufficient evidence to suggest that 
there is an association between the two variables.

**Independence of political party and sentiment:** In order to determine whether 
the variables party (the political affiliation of the person discussed) and 
posNeg (categorical sentiment of the tweet) are dependent, a chi-square test was 
used. The null hypothesis, $H_0$, is that the party of the person discussed and 
the categorical sentiment of the tweet are independent, or in other words, there 
is no association between the two variables. This is being tested against the 
alternative hypothesis, which is that the party of the person discussed and the 
categorical sentiment of the tweet are dependent, or in other words, there is an 
association between the two variables. We used the chi-square test to conduct 
this hypothesis test at the $alpha$ = 0.05 significance level. Under the 
assumption that the null hypothesis is true, the chi-square test statistic 
follows a Chi-square distribution with degrees of freedom equal to 
(2-1)x(3-1) = (1)x(2) = 2. The value of our test statistic, chi-square, is 
173.34. The p-value of our chi-square test is less than 2.2e-16, which is close 
to zero and less than the significance level of 0.05. This means we reject the 
null hypothesis. In the context of the data, we are concluding that there is 
sufficient evidence to suggest that the party of the person discussed and the 
categorical sentiment are dependent or that there is sufficient evidence to 
suggest that there is an association between the two variables.

Since the results of our chi-square test suggested that there is a dependent 
relationship between these two variables, we decided to further investigate the 
relationship between party and the sentiment of Trump’s Tweet. To do this we 
conducted a Central Limit Theorem t-test.

**Sentiment across political party:** For the purposes of this test, we define
in-group as Republicans, and out-group as Democrats. While Amy Coney Barrett and
Anthony Fauci are not publicly affiliated with any particular party, we
categorized them as Republican and Democrat respectively for the purposes of 
this test. In order to determine if the true mean 
sentiment score of Donald Trump's tweets about Democratic politicians is less 
than the mean sentiment score of Donald Trump's tweets about Republican 
politicians, a CLT-based t-test was used. The null hypothesis, $H_0$, is that 
the true mean sentiment score of Donald Trump's tweets about Democratic 
politicians is equal to the true mean sentiment score of Donald Trump's tweets 
about Republican politicians. This is being tested against the alternative 
hypothesis, $H_1$, which is that the true mean sentiment score of Donald Trump's 
tweets about Democratic politicians is less than the true mean sentiment score 
of Donald Trump's tweets about Republican politicians. We used the Central Limit 
Theorem to conduct this hypothesis test at the $\alpha$ = 0.05 significance 
level. We know that we can use the CLT because our observations are 
independently selected and our sample size is greater than 30 which means we can 
expect the CLT to apply. The CLT tells us that we will have a t distribution 
with 469.92 degrees of freedom since we do not have the population standard 
deviation ($\sigma$) of sentiment scores. Under the null hypothesis, we also 
know that the distribution of the test statistic can be approximated by a normal 
distribution which means that it is unimodal, symmetric, and centered at zero.
The value of out test statistic, t, is -14.678. Our p-value is less than 
2.2e-16, which is very close to zero and less than our $\alpha$ of 
0.05. This means that we reject the null hypothesis.
In the context of our data, this tells us that there is sufficient evidence to 
suggest that the true mean sentiment score of Donald Trump's 
tweets about Democratic politicians is less than the true mean sentiment score 
of Donald Trump's tweets about Republican politicians.


**Independence of gender and sentiment:** In order to determine whether the 
variables gender (the gender of the person 
discussed) and posNeg (categorical sentiment of the tweet) are dependent, a 
chi-square test was used. The null hypothesis, $H_0$, is that the gender of the 
person discussed and the categorical sentiment of the tweet are independent, or 
in other words, there is no association between the two variables. This is being 
tested against the alternative hypothesis, which is that the gender of the 
person discussed and the categorical sentiment of the tweet are dependent, or in 
other words, there is an association between the two variables. We used the 
chi-square test to conduct this hypothesis test at the $alpha$ = 0.05 
significance level. Under the assumption that the null hypothesis is true, the 
chi-square test statistic follows a Chi-square distribution with degrees of 
freedom equal to (2-1)x(3-1) = (1)x(2) = 2. The value of our test statistic, 
chi-square, is 27.151. The p-value of our chi-square test is 1.271e-6, which is 
close to zero and less than the significance level of 0.05. This means we reject 
the null hypothesis. In the context of the data, we are concluding that there is 
sufficient evidence to suggest that the gender of the person discussed and the 
categorical sentiment are dependent or that there is sufficient evidence to 
suggest that there is an association between the two variables.

Since the results of our chi-square test suggested that there is a dependent 
relationship between these two variables, we decided to further investigate the 
relationship between gender and the sentiment of Trump’s Tweet. To do this we 
conducted a Central Limit Theorem t-test.

**Sentiment across gender:** For the purposes of this test, we define
in-group as males, and out-group as females In order to determine if the true 
mean sentiment score of Donald Trump's tweets about male politicians is greater 
than the mean sentiment score of Donald Trump's tweets about female 
politicians, a CLT-based t-test was used. The null hypothesis, $H_0$, is that 
the true mean sentiment score of Donald Trump's tweets about male 
politicians is equal to the true mean sentiment score of Donald Trump's tweets 
about female politicians. This is being tested against the alternative 
hypothesis, $H_1$, which is that the true mean sentiment score of Donald Trump's 
tweets about male politicians is greater than the true mean sentiment score 
of Donald Trump's tweets about female politicians. We used the Central Limit 
Theorem to conduct this hypothesis test at the $\alpha$ = 0.05 significance 
level. We know that we can use the CLT because our observations are 
independently selected and our sample size is greater than 30 which means we can 
expect the CLT to apply. The CLT tells us that we will have a t distribution 
with 3900.6 degrees of freedom since we do not have the population standard 
deviation ($\sigma$) of sentiment scores. Under the null hypothesis, we also 
know that the distribution of the test statistic can be approximated by a normal 
distribution which means that it is unimodal, symmetric, and centered at zero.
The value of out test statistic, t, is 6.6948. Our p-value is 1.234e-11, 
which is very close to zero and less than our $\alpha$ of 
0.05. This means that we reject the null hypothesis.
In the context of our data, this tells us that there is sufficient evidence to 
suggest that the true mean sentiment score of Donald Trump's 
tweets about male politicians is greater than the true mean sentiment score 
of Donald Trump's tweets about female politicians.

W categorized each of the topics we explored as in-group vs. out-group based
on his historical stances/statements about each of them. 
We categorized USA, guns, and Russia as "in-group", and
immigration, abortion, BLM, COVID, climate change, and news as "out-group."
From the percent stacked bar chart comparing sentiment and topic we found that 
there was no clear distinction between the sentiments in the in-group and 
out-group, which prompted us to investigate further, looking into how his
sentiments towards certain topics have changed over time. We were interested
specifically in how these changed from before his election (pre-2016) to
after it (2016-present).

**CLIMATE CHANGE - Sentiment before and after election:** In order to 
determine if the true mean sentiment score of Donald Trump’s Tweets about 
climate change changed before and after he was elected president, a CLT-based 
t-test was used. The null hypothesis, $H_0$, is that the difference between the 
true mean sentiment score of Donald Trump’s Tweets about climate change before 
and after the election is equal to 0. This is being tested against the 
alternative hypothesis, $H_1$, which is that the difference of true mean 
sentiment score of Donald Trump’s Tweets about climate change between before the 
election and after the election is not equal to 0. We used the Central Limit 
Theorem to conduct this hypothesis test at the $alpha$ = 0.05 significance 
level. We know that we can use the CLT because our observations are 
independently selected and our sample size is greater than 30 which means we can 
expect the CLT to apply. The CLT tells us that we will have a t distribution 
with 107.75 degrees of freedom since we do not have the population standard 
deviation of sentiment scores. Under the null hypothesis, we also know that it 
is unimodal, symmetric, and centered at zero. The value of our test statistic, 
t, is -3.5886. Our p-value is 0.0005017, which is very close to zero and less 
than our $alpha$ of 0.05. This means we reject the null hypothesis. In the 
context of our data, this tells us that there is sufficient evidence to suggest 
that the difference of true mean sentiment score of Donald Trump’s Tweets about 
climate change between before the election and after the election is not equal 
to 0.

**GUNS - Sentiment before and after election:** In order to determine if the 
true mean sentiment score of Donald Trump’s Tweets about guns changed before and 
after he was elected president, a CLT-based t-test was used. The null 
hypothesis, $H_0$, is that the difference of true mean sentiment score of Donald 
Trump’s Tweets about guns between before the election and after the election is 
equal to 0. This is being tested against the alternative hypothesis, $H_1$, 
which is that the difference of true mean sentiment score of Donald Trump’s 
Tweets about guns between before the election and after the election is not 
equal to 0. We used the Central Limit Theorem to conduct this hypothesis test at 
the $alpha$ = 0.05 significance level. We know that we can use the CLT because 
our observations are independently selected and our sample size is greater than 
30 which means we can expect the CLT to apply. The CLT tells us that we will 
have a t distribution with 191.94 degrees of freedom since we do not have the 
population standard deviation of sentiment scores. Under the null hypothesis, we 
also know that it is unimodal, symmetric, and centered at zero. The value of our 
test statistic, t, is -1.4058. Our p-value is 0.1614, which is greater than our 
$alpha$ of 0.05. This means we fail to reject the null hypothesis. In the 
context of our data, this tells us that there is not sufficient evidence to 
suggest that the difference of true mean sentiment score of Donald Trump’s 
Tweets about guns between before the election and after the election is not 
equal to 0.

**IMMIGRATION - Sentiment before and after election:** In order to determine if 
the true mean sentiment score of Donald Trump’s Tweets about immigration changed 
before and after he was elected president, a CLT-based t-test was used. The null 
hypothesis, $H_0$, is that the difference of true mean sentiment score of Donald 
Trump’s Tweets about immigration between before the election and after the 
election is equal to 0. This is being tested against the alternative hypothesis, 
$H_1$, which is that the difference of true mean sentiment score of Donald 
Trump’s Tweets about immigration between before the election and after the 
election is not equal to 0. We used the Central Limit Theorem to conduct this 
hypothesis test at the $alpha$ = 0.05 significance level. We know that we can 
use the CLT because our observations are independently selected and our sample 
size is greater than 30 which means we can expect the CLT to apply. The CLT 
tells us that we will have a t distribution with 5227.9 degrees of freedom since 
we do not have the population standard deviation of sentiment scores. Under the 
null hypothesis, we also know that it is unimodal, symmetric, and centered at 
zero. The value of our test statistic, t, is 14.158. Our p-value is less than 
2.2e-16, which is very close to zero and less than our $alpha$ of 0.05. This 
means we reject the null hypothesis. In the context of our data, this tells us 
that there is sufficient evidence to suggest that the difference of true mean 
sentiment score of Donald Trump’s Tweets about immigration between before the 
election and after the election is not equal to 0.

**NEWS - Sentiment before and after election:** In order to determine if the 
true mean sentiment score of Donald Trump’s Tweets about the news changed before 
and after he was elected president, a CLT-based t-test was used. The null 
hypothesis, $H_0$, is that the difference of true mean sentiment score of Donald 
Trump’s Tweets about the news between before the election and after the election 
is equal to 0. This is being tested against the alternative hypothesis, $H_1$, 
which is that the difference of true mean sentiment score of Donald Trump’s 
Tweets about the news between before the election and after the election is not 
equal to 0. We used the Central Limit Theorem to conduct this hypothesis test at 
the $alpha$ = 0.05 significance level. We know that we can use the CLT because
our observations are independently selected and our sample size is greater than 
30 which means we can expect the CLT to apply. The CLT tells us that we will 
have a t distribution with 3938 degrees of freedom since we do not have the 
population standard deviation of sentiment scores. Under the null hypothesis, 
we also know that it is unimodal, symmetric, and centered at zero. The value of 
our test statistic, t, is 14.018. Our p-value is less than 2.2e-16, which is 
very close to zero and less than our $alpha$ of 0.05. This means we reject the 
null hypothesis. In the context of our data, this tells us that there is 
sufficient evidence to suggest that the difference of true mean sentiment score 
of Donald Trump’s Tweets about the news between before the election and after 
the election is not equal to 0.

## Discussion
From our initial analyses of Trump’s word choice, it became clear that Trump’s 
tweets frequently contain words that come across as more polarized, strongly 
exemplifying his sentiment. For example, he uses positive words like “great,” 
“big,” and “good” commonly while also using negative words such as “false,” and 
“fake” fairly often. In addition, he frequently addresses both himself and those 
who support him while also speaking about people or news outlets that oppose 
him. 

Sentiment analysis across Donald Trump’s Tweets has provided evidence that, when 
it comes to people, Trump does Tweet more positively about his in-groups than 
his out-groups. We defined these in-groups and out-groups in multiple ways. The 
first way that we defined it was based on political party, meaning that 
Republicans like McConnell and Pence were in the in-group and Democrats such as 
Joe Biden and AOC were considered to be members of the out-group. While they 
don’t technically have a political party affiliation, we categorized Amy 
Coney-Barrett as in-group and Anthony Fauci as out-group based on what is known 
publicly about their relationships with President Trump. Through our 
visualizations and hypothesis tests, we observed that there was enough evidence 
to suggest that the true mean average sentiment of Tweets about Democratic 
politicians was lower than those about Republicans. 

Similarly, when considering in-groups and out-groups by gender, Trump once 
again had significantly more positive sentiment towards his in-group - in this 
case, fellow males. While there were clear differences between in-group and 
out-group sentiment when considering people, the divisions were not as obvious 
among topics. We tried to define topics by in-group and out-group as well, 
assigning things that are traditionally viewed by Trump and Republicans in a 
positive light as the in-group and vice versa. For example, guns and the United 
States were considered topics in Trump’s in-group while abortion and the Black 
Lives Matter movement fell in the out-group.  When comparing overall sentiments 
about topics, however, it was difficult to see any clear difference between 
topics that we expected him to feel positively towards and those we did not. In 
fact, in a few cases, his sentiment was generally positive on topics that we 
expected to fall securely in the out-group, contradicting our hypothesis that he 
would be negative on these subjects overall. Trump’s sentiment across specific 
topics over the years gives us insight into his thoughts on many prevalent 
issues. Starting from the year 2009, Trump’s overall sentiment towards 
immigration and news follow similar patterns, suggesting that Trump’s viewpoints 
on those subjects may follow a similar pattern. Additionally, after Trump was 
elected president in 2016, his average sentiment score towards immigration, 
climate change, and the news changed significantly, whereas his average 
sentiment score towards guns did not.

**Potential improvements for the analysis:**
Although we filtered tweets by keywords, there are likely situations in which 
Trump addresses members of both political parties in one tweet. With our current 
model, those tweets would be included in the analysis of both Democratic and 
Republican politicians, which would skew the data. In order to keep data 
analysis objective, tweets that involve both parties should be removed from the 
dataset. Overcounting or missing certain keywords is also a potential issue. For 
example, Mike is a common name, and it is possible that some of the tweets that 
were included are referring to other politicians with the name Mike other than 
Mike Pence.

In the study, only tweets regarding 11 politicians were used. Although there is 
still a large amount of tweets to analyze, the number of politicians was 
somewhat limited and increasing the number of Democratic and Republican 
politicians would allow us to draw more representative conclusions.

When tweets were categorized by sentiment, they were all classified as either 
positive or negative unless their sentiment score was exactly 0. As a result, a 
slight positive or negative sentiment could be misleading as it is classified in 
the same category as an extremely positive or negative sentiment. Perhaps a 
range of scores should be considered as neutral in order to prevent 
misinterpretation of the data.

A different sentiment package in which we could specify a lexicon tailored to 
political contexts would also potentially improve results - for example one that 
is commonly used to conduct sentiment analysis for political debates.
Finally, in addition to an overall analysis on Trump’s sentiments towards many 
issues, a further analysis on his change in sentiment over time could give 
valuable information. For example, analysis on Trump’s change in sentiments 
towards guns during periods of school shootings and subsequent analysis of the 
popularity of those tweets could potentially reveal whether he promoted unity or 
increased divisiveness during controversial times.

**Limitations of the analysis:**
Sentiment analysis is not a perfectly objective measure of one’s thought on an 
issue, because the analysis is based on analyzing individual words rather than 
taking the context as a whole. The overall sentiment score is the mean sentiment 
of the text, which can be misleading when tweets contain both strongly negative 
and positive words; in this case, the score would suggest that the sentiment is 
neutral when the reality is that the sentiment is likely emotionally charged. 
Sarcasm is another issue that challenges sentiment analysis. Often, people on 
Twitter use positive words to portray their negative thoughts through sarcasm, 
which could lead to an inaccurate interpretation of the intended sentiment.

Another limitation that we noticed while conducting our analyses was that it is 
challenging to categorize topics as “in-group” or “out-group.” Because there are 
multiple sides to each of the issues that we looked at, it is possible that 
Trump would tweet both positively and negatively about a certain topic, as he 
likely falls on one side of the debate. For example, we categorized guns as 
“in-group”, and while it is likely that he tweets positively about second 
amendment rights, he may tweet negatively about gun control. Both of these 
types of tweets would fall under the same category of “guns”, pulling the 
overall sentiment closer to neutrality, despite his tweets only representing one 
side of the debate.

Finally, because the data is correlational, we cannot draw causal relationships. 
Given that a politician is a Democrat, we can plausibly anticipate that Trump’s 
sentiment score will be lower than if he were a Republican, but we cannot say 
with definitive evidence that it would.


## Sources
http://www.trumptwitterarchive.com/about

https://www.journalism.org/2016/05/26/news-use-across-social-media-platforms-
2016/

https://www.realclearpolitics.com/articles/2019/09/11/numbers_show_how_trumps_
tweets_drive_the_news_cycle_141217.html

https://en.wikipedia.org/wiki/List_of_most-followed_Twitter_accounts

https://twitter.com/realDonaldTrump?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7
Ctwgr%5Eauthor



